{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_models(model_paths, device, label_dicts):\n",
    "    models = {}\n",
    "    for model_name, model_path in model_paths.items():\n",
    "        label_dict = label_dicts[model_name]\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                            num_labels=len(label_dict),\n",
    "                                                            output_attentions=False,\n",
    "                                                            output_hidden_states=False)\n",
    "\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(f'{model_path}', map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "        models[model_name] = model\n",
    "    return models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification \n",
    "def predict(inputs, model, label_dict):   \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predicted_class_idx = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    \n",
    "    for label, idx in label_dict.items():\n",
    "        if idx == predicted_class_idx:\n",
    "            predicted_class = label\n",
    "            break\n",
    "    return predicted_class\n",
    "\n",
    "def label_exists(label, dictionary):\n",
    "    return label in dictionary\n",
    "\n",
    "def prediction_runner(inputs, models, label_dicts, label):\n",
    "    if label_exists(label, label_dicts):\n",
    "        model = models[label]\n",
    "        label_dict = label_dicts[label]\n",
    "        new_label = predict(inputs, model, label_dict)\n",
    "        label = prediction_runner(inputs, models, label_dicts, new_label)\n",
    "    return label\n",
    "    \n",
    "    \n",
    "\n",
    "def prediction_loop(text, models, label_dicts):\n",
    "    # Check if item is or is not a Grocery Item\n",
    "    print(f'Got the text {text}')\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    model = models['is_grocery']\n",
    "    label_dict = label_dicts['is_grocery']\n",
    "    l1_pred = predict(inputs, model, label_dict)\n",
    "\n",
    "    if l1_pred == 'GROC':\n",
    "        model = models['food_beverage']\n",
    "        label_dict = label_dicts['food_beverage']\n",
    "        l2_pred = predict(inputs, model, label_dict)\n",
    "        if l2_pred:\n",
    "            label = prediction_runner(inputs, models, label_dicts, l2_pred)\n",
    "            return label\n",
    "        else:\n",
    "            return \"Critical Error\"\n",
    "    return l1_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Main \n",
    "label_dicts = {\n",
    "    \"is_grocery\" : {'GROC': 0, 'NONG': 1},\n",
    "    \"food_beverage\" : {'FDAA': 0, 'BEVA': 1},\n",
    "    \"FDAA\" : {'BAKA': 0,'MISC': 1,'ANIP': 2,'FRTV': 3,'CUFD': 4,},\n",
    "    \"BEVA\" : {'SODR': 0, 'WATR': 1, 'CTCC': 2},\n",
    "    \"SODR\" : {'FIZD': 0, 'ENRD': 1, 'FRUJ': 2},\n",
    "    \"WATR\" : {'FLWR': 0, 'SMWR': 1},\n",
    "    \"CTCC\" : {'COFF': 0, 'HTCD': 1, 'SBTB': 2},\n",
    "    \"BAKA\" : {'BAKY': 0, 'BKGD': 1},\n",
    "    \"MISC\" : {'CHSW': 0, 'JAMH': 1, 'SAUC': 2},\n",
    "    \"ANIP\" : {'DAIR': 0, 'FISH': 1, 'MEAT': 2},\n",
    "    \"FRTV\" : {'FRFR': 0, 'FRVG': 1, 'POTA': 2},\n",
    "    \"CUFD\" : {'BRKF': 0, 'BSOI': 1, 'CANF': 2, 'RICE': 3},\n",
    "    \"BAKY\" : {'BRRL': 0, 'INCK': 1, 'PKWT': 2, 'WHBR': 3, 'WHMB': 4},\n",
    "    \"BKGD\" : {'SRFL': 0, 'OTFL': 1, 'PWSU': 2},\n",
    "    \"CHSW\" : {'CHOC': 0, 'GUMM': 1, 'OTSW': 2},\n",
    "    \"JAMH\" : {'HONY': 0, 'JAMM': 1, 'CRSP': 2},\n",
    "    \"DAIR\" : {'CHCH': 0, 'EGGS': 1, 'SKML': 2, 'SFCH': 3, 'WHMK': 4},\n",
    "    \"FISH\" : {'FSFF': 0, 'FWFF': 1, 'PRAW': 2},\n",
    "    \"MEAT\" : {'PORK': 0, 'BEEF': 1, 'CHCK': 2, 'TURK': 3},\n",
    "    \"FRFR\" : {'AVOC': 0, 'BANA': 1, 'BLUE': 2, 'APPL': 3, 'GRAP': 4, 'KIWI': 5, 'LEMN': 6, 'ORNG': 7, 'PINE': 8, 'PLUM': 9, 'RASP': 10},\n",
    "    \"FRVG\" : {'BROC': 0, 'CARR': 1, 'CAUL': 2, 'CUCU': 3, 'LETT': 4, 'MUSH': 5, 'ONIO': 6, 'PEPP': 7, 'TOMA': 8, 'MXVG': 9},\n",
    "    \"POTA\" : {'POTT': 0, 'SWPT': 1},\n",
    "    \"BRKF\" : {'BCGF': 0, 'BCER': 1},\n",
    "    \"BSOI\" : {'BUTT': 0, 'MARG': 1, 'OLOL': 2},\n",
    "    \"CANF\" : {'CTUN': 0, 'BKBN': 1, 'CNFR': 2},\n",
    "    \"RICE\" : {'BSRX': 0, 'JSRX': 1, 'LGRX': 2},\n",
    "  \n",
    "}\n",
    "model_paths = {\n",
    "    \"is_grocery\" : \"models/is_grocery_bert.model\",\n",
    "    \"food_beverage\" : \"models/food_beverage_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"FDAA\" : \"models/fdaa_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BEVA\" : \"models/beva_models/finetuned_BERT_epoch_4.model\",\n",
    "    \"SODR\" : \"models/sodr_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"WATR\" : \"models/watr_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"CTCC\" : \"models/ctcc_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BAKA\" : \"models/baka_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"MISC\" : \"models/misc_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"ANIP\" : \"models/anip_models/finetuned_BERT_epoch_3.model\",\n",
    "    \"FRTV\" : \"models/frtv_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"CUFD\" : \"models/cufd_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BAKY\" : \"models/baky_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BKGD\" : \"models/bkgd_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"CHSW\" : \"models/chsw_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"JAMH\" : \"models/jamh_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"DAIR\" : \"models/dair_models/finetuned_BERT_epoch_3.model\",\n",
    "    \"FISH\" : \"models/fish_models/finetuned_BERT_epoch_4.model\",\n",
    "    \"MEAT\" : \"models/meat_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"FRFR\" : \"models/frfr_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"FRVG\" : \"models/frvg_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"POTA\" : \"models/pota_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BRKF\" : \"models/brkf_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"BSOI\" : \"models/bsoi_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"CANF\" : \"models/canf_models/finetuned_BERT_epoch_5.model\",\n",
    "    \"RICE\" : \"models/rice_models/finetuned_BERT_epoch_3.model\",\n",
    "}\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "models = load_models(model_paths, device, label_dicts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the text Panini 4 Pack\n",
      "Got the text Tesco Chunky Cheese Rolls 4 Pack\n",
      "Got the text Ciabatta Roll 4 Pack\n",
      "Got the text St Pierre 6 Brioche Burger Buns\n",
      "Got the text Tesco Large White Hot Dog Rolls 6 Pack\n",
      "Got the text Big Bite Soft White Roll 6Pack\n",
      "Got the text 6 Pack White Finger Rolls\n",
      "Got the text 6 Pack Soft White Rolls\n",
      "Got the text Large White Bap 4 Pack\n",
      "Got the text Baker Street Burger Buns 6 Pack\n",
      "Got the text Baker Street 4 Hot Dog Rolls\n",
      "Got the text Tesco Finest 4 Mango  Passion Fruit Buttermilk Pancakes\n",
      "Got the text Warburtons Sliced Sandwich Rolls 12 Pack\n",
      "Got the text Tesco Finest 4 Onion Brioche Hot Dog Rolls\n",
      "Got the text Tesco Finest 4 Brioche Burger Buns\n",
      "Got the text Tesco Wholemeal Deli Rolls 4 Pack\n",
      "Got the text Warburtons Hot Dog Rolls X 6\n",
      "Got the text Tesco Fire Pit 6 Jumbo Brioche Hot Dog Rolls\n",
      "Got the text Tesco 4 Brioche Buns\n",
      "Got the text Tesco Finest 2 Turmeric Brioche Burger Buns\n",
      "Got the text Warburtons 6 Sliced Sandwich Rolls\n",
      "Got the text Tesco Large Wholemeal Baps 4 Pack\n",
      "Got the text Tesco 4 Large White Baps\n",
      "Got the text Tesco Large Seeded Burger Buns 4 Pack\n",
      "Got the text Tesco Finest 6 Mini Brioche Buns\n",
      "Got the text Tesco Wholemeal Batch Rolls 6 Pack\n",
      "Got the text Tesco White Batch Rolls 6 Pack\n",
      "Got the text Bfree Demi Baguette 2 Pack 220G\n",
      "Got the text New York Bakery Co. Bagels, Plain x5\n",
      "Got the text New York Bakery Co. Onion & Chive Bagels x5\n",
      "Got the text Paul Hollywood Ready to Bake Multi-Seed Rolls x4\n",
      "Got the text New York Bakery Co. Bagels, Plain x5\n",
      "Got the text New York Bakery Co. Bagels, Cinnamon & Raisin x5\n",
      "Got the text St. Pierre Brioche Burger Buns x6\n",
      "Got the text Warburtons 4 Seeded Protein Thin Bagels\n",
      "Got the text Daily's White Rolls x4 300g\n",
      "Got the text Sainsbury's Mini Ciabatta Roll\n",
      "Got the text Warburtons Sliced White Rolls x12\n",
      "Got the text Daily's Wholemeal Rolls x4 300g\n",
      "Got the text Warburtons Gluten Free Super Soft Sliced Square Rolls x4 240g\n",
      "Got the text Sainsbury's Stonebaked Ciabatta Rolls x4\n",
      "Got the text Schar Gluten Free Brown Ciabatta Rolls x4\n",
      "Got the text Sainsbury's Artisan Seeded Sourdough Pave, Taste the Difference 400g\n",
      "Got the text Sainsbury's Super Seed Grain Large Rolls Taste the Difference x4\n",
      "Got the text Warburtons 6 Soft Sliced White Rolls\n",
      "Got the text Plant Pioneers Brioche Style Burger Buns x2 140g\n",
      "Got the text New York Bakery Co. Bagels, Wholemeal x5\n",
      "Got the text Schar Gluten Free White Ciabatta Rolls x4\n",
      "Got the text Sheldons Brown Oven Bottom Muffins x4\n",
      "Got the text Warburtons 6 Soft Sliced Wholemeal Rolls\n",
      "Got the text Genius White Rolls 280g\n",
      "Got the text Sainsbury's Super Seed Grain Rolls Taste the Difference x6\n",
      "Got the text Sainsbury's Plain Bagel x5\n",
      "Got the text Bfree Tiger Rolls 4x60g\n",
      "Got the text St Pierre Burger Buns x4\n",
      "Got the text Genius Ciabatta Rolls x2\n",
      "Got the text Mr Kipling Manor House Cake Each\n",
      "Got the text Tesco Finest Free From Carrot Cake\n",
      "Got the text Mr Kipling Lemon Loaf Cake  Crumble 210G\n",
      "Got the text Tesco Free From Lemon Loaf Cake\n",
      "Got the text Tesco Angel Layer Cake Each\n",
      "Got the text Tesco Banana Loaf Cake\n",
      "Got the text Tesco Lemon Loaf Cake\n",
      "Got the text Tesco Coconut  Raspberry Loaf Cake\n",
      "Got the text Soreen Sliced Malt Loaf 290G\n",
      "Got the text Norfolk Cake Co Mixed Fruit Loaf Cake\n",
      "Got the text Tesco Raspberry Sponge Cake Each\n",
      "Got the text Tesco Coconut Sponge Cake Each\n",
      "Got the text Tesco Iced Coffee Cake\n",
      "Got the text Tesco Genoa Cake Each\n",
      "Got the text Tesco Lemon Iced Madeira Cake Each\n",
      "Got the text Tesco Strawberry Jam Victoria Sponge 360G\n",
      "Got the text Tesco Strawberry  Cream Swiss Roll\n",
      "Got the text Soreen Original Malt Loaf 260G\n",
      "Got the text Tesco Madeira Cake\n",
      "Got the text Tesco Lemon Swiss Roll\n",
      "Got the text Tesco Walnut Cake\n",
      "Got the text Soreen Banana Loaf 260G\n",
      "Got the text Tesco Iced Madeira Cake Each\n",
      "Got the text Tesco Chocolate Brownie Bar Cake\n",
      "Got the text Mcvities Jamaica Ginger Cake Each\n",
      "Got the text Mcvities Original Lyles Golden Syrup Cake\n",
      "Got the text Tesco Finest Chocolate Cake\n",
      "Got the text Tesco Double Chocolate Swiss Roll\n",
      "Got the text Tesco Chocolate Mega Loaf\n",
      "Got the text Tesco Finest Lemon Drizzle Cake Each\n",
      "Got the text Tesco Finest Coffee  Walnut Cake Each\n",
      "Got the text Ms Mollys Raspberry Swiss Roll\n",
      "Got the text Sainsbury's Victoria Sponge Cake, Taste the Difference 345g (Serves 6)\n",
      "Got the text Sainsbury's Colombian Coffee Cake, Taste the Difference 400g (Serves 6)\n",
      "Got the text Sainsbury's Cherry Bakewells x6 240g\n",
      "Got the text Sainsbury's Chocolate Cake, Taste The Difference 395g (Serves 6)\n",
      "Got the text Sainsbury's Carrot Cake, Taste the Difference 395g (Serves 6)\n",
      "Got the text Sainsbury's Lemon Cake, Taste the Difference 405g\n",
      "Got the text Sainsbury's Jaffa Cakes x24 282g\n",
      "Got the text Real Lancashire Eccles Cakes x4\n",
      "Got the text Sainsbury's Fresh Custard Slices x2 180g\n",
      "Got the text Sainsbury's Cherry Madeira Cake (Serves 8)\n",
      "Got the text Sainsbury's Walnut Cake (Serves 8)\n",
      "Got the text Sainsbury's Lemon Iced Madeira Cake (Serves 8)\n",
      "Got the text Sainsbury's Strawberry Jam & Cream Victoria Sponge 340g\n",
      "Got the text Mr Kipling Manor House Cake 390g (Serves 6)\n",
      "Got the text Sainsbury's Madeira Cake 275g (Serves 8)\n",
      "Got the text Sainsbury's Angel Cake 250g\n",
      "Got the text Bfree Sweet Potato Gluten Free Wrap 6X42g\n",
      "Got the text Warburtons Gluten Free White Wraps 4 Pack\n",
      "Got the text Old El Paso 6 Regular Gluten Free Tortilla 216G\n",
      "Got the text Old El Paso 8 Tortilla Pockets 223G\n",
      "Got the text Capsicana 6 Large Tortilla Wheat Flour Wraps 390G\n",
      "Got the text Old El Paso Stand N Stuff Soft Flour Tortillas 8Pk 193G\n",
      "Got the text Capsicana 8 Mini Tortilla Wheat Flour Wraps 240G\n",
      "Got the text Old El Paso Large Super Soft Flour Tortillas 6 Pack 350G\n",
      "Got the text Weight Watchers Wraps 6 Pack\n",
      "Got the text Deli Kitchen 4 Sliced Focaccia 360G\n",
      "Got the text Crosta  Mollica 6 Durum Wheat Piadina Midi Flatbreads 240G\n",
      "Got the text Crosta  Mollica 6 Whole Blend Piadina Midi Flatbreads 240G\n",
      "Got the text Deli Kitchen 4 Greek Style Flatbreads 320G\n",
      "Got the text Mission Deli 6 Wheat  White Mini Wraps\n",
      "Got the text Old El Paso Super Soft Flour Tortillas Whole Wheat 8Pk 326G\n",
      "Got the text Mission Deli Mini Wrap Original 6 Pack\n",
      "Got the text Old El Paso Regular Super Soft Flour Tortillas 8Pk 326G\n",
      "Got the text Mission Deli Wheat  White Wraps 6 Pack 367G\n",
      "Got the text Mission Deli Original Wraps Super Soft 6 Pack 367G\n",
      "Got the text Tesco 8 Mini White Tortilla Wraps\n",
      "Got the text Old El Paso Corn Tortillas 335G\n",
      "Got the text Deli Kitchen 6 Brioche Style Tortilla Wraps 366G\n",
      "Got the text Tesco Folded Flatbreads Plain 6 Pack\n",
      "Got the text Tesco Malted Grain  Rye Folded Flatbread 6 Pack\n",
      "Got the text Tesco 8 Plain Tortilla Wraps\n",
      "Got the text Tesco 8 Wholemeal Tortilla Wraps\n",
      "Got the text Deli Kitchen 6 Carb Lite Wraps 300G\n",
      "Got the text HW Nevills 8 Plain Tortilla Wraps\n",
      "Got the text HW Nevills 8 Wholemeal Tortilla Wrap\n",
      "Got the text Crosta & Mollica Piadina Golden Durum Wheat Italian Flatbreads Wraps x4 300g\n",
      "Got the text Old El Paso Large Soft Flour Tortilla Wraps x6 350g\n",
      "Got the text Crosta & Mollica Piadina Organic Wholeblend Italian Flatbreads Wraps x4 300g\n",
      "Got the text Old El Paso Regular Soft Flour Tortilla Wraps x8 326g\n",
      "Got the text Deli Kitchen Carb Lite Wraps x6 300g\n",
      "Got the text Mission Deli Mini Plain Tortillas x6\n",
      "Got the text Mission Deli Wrap Wheat & White x6\n",
      "Got the text Sainsbury's Mini Tortilla Wraps x8\n",
      "Got the text Friend Birthday Card Pink with Cute Character and Sentiment Greeting Card\n",
      "Got the text Old El Paso Regular Soft Whole Wheat Tortilla Wraps x8 326g\n",
      "Got the text Sainsbury's Plain Tortilla Wraps x8\n",
      "Got the text Warburtons Gluten Free White Wraps x4\n",
      "Got the text Sainsbury's Wholemeal Tortilla Wraps x8\n",
      "Got the text Sainsbury's Non Stick Baking Sheets x20\n",
      "Got the text Mission Deli Wrap Plain x6\n",
      "Got the text BFree Sweet Potato Wraps x6\n",
      "Got the text Mission Deli Mini Wraps x6 186g\n",
      "Got the text Old El Paso Regular Soft Flour Tortilla Wraps x12 489g\n",
      "Got the text Old El Paso Mexican Tortilla Wrap Pockets x8 223g\n",
      "Got the text Sainsbury's Plain Flour Tortillas x8 320g\n",
      "Got the text Sainsbury's Wholemeal Tortilla Wraps x8 512g\n",
      "Got the text Sainsbury's Plain Tortilla Wraps x8 496g\n",
      "Got the text Tesco Crusty White Farmhouse Loaf Sliced 800G\n",
      "Got the text Tiger Loaf Sliced 800G\n",
      "Got the text Crusty White Sandwich Loaf Sliced 800G\n",
      "Got the text Tiger Loaf Sliced 400G\n",
      "Got the text Warburtons Sliced Tiger Bread 600G\n",
      "Got the text Warburtons Farmhouse White Bread 800G\n",
      "Got the text Warburtons Old English White Bread 400G\n",
      "Got the text Kingsmill Soft White Medium Bread 800G\n",
      "Got the text Hovis Soft White Medium Bread 800G\n",
      "Got the text Hovis Soft White Thick Bread 800G\n",
      "Got the text Warburtons Toastie Sliced White Bread 800G\n",
      "Got the text Warburtons Medium Sliced White Bread 800G\n",
      "Got the text Tesco Finest White Loaf With Sourdough 800G\n",
      "Got the text Tesco White Farmhouse 800G\n",
      "Got the text Tesco Toastie White Bread Thick 800G\n",
      "Got the text Tesco White Bread 800G\n",
      "Got the text H W Nevills White Bread 800G\n",
      "Got the text White Farmhouse 800G\n",
      "Got the text Tiger Bloomer 800G\n",
      "Got the text Crusty White Sandwich Loaf 800G\n",
      "Got the text Tiger Bloomer 400G\n",
      "Got the text Crusty White Farmhouse Loaf 400G\n",
      "Got the text Crusty White Split Tin 800G\n",
      "Got the text Crusty White Bloomer 800G\n",
      "Got the text Petit Pain 4 Pack\n",
      "Got the text Crusty White Bloomer 400G\n",
      "Got the text Warburtons Milk Roll Soft Medium Sliced White Bread 400g\n",
      "Got the text Hovis Soft Medium Sliced White Bread 800g\n",
      "Got the text Black Sheep Craft White Bloomer 800g\n",
      "Got the text Black Sheep Craft Tiger Bloomer 800g\n",
      "Got the text Schar White Wholesome Loaf 300g\n",
      "Got the text Jason's Sourdough White Ciabattin 580g\n",
      "Got the text Hovis Soft Thick Sliced White Bread 800g\n",
      "Got the text Kingsmill Soft White Bread Thick 800g\n",
      "Got the text Warburtons Premium Old English White Bread 400g\n",
      "Got the text Warburtons Extra Thick Sliced White Bread 800g\n",
      "Got the text Sainsbury's White Sourdough Bloomer Thick Sliced, Taste the Difference 800g\n",
      "Got the text Sainsbury's Free From White Sliced Loaf 535g\n",
      "Got the text Warburtons Soft Farmhouse Thick Sliced White Bread 800g\n",
      "Got the text Hovis Farmhouse 800g\n",
      "Got the text Kingsmill No Crusts Soft Medium Sliced White Bread 400g\n",
      "Got the text Warburtons White Batch Bloomer 800g\n",
      "Got the text Sainsbury's Multiseed Loaf, Taste the Difference 800g\n",
      "Got the text Sainsbury's Wholemeal Bread SO Organic 400g\n",
      "Got the text Sainsbury's Sourdough Pave, Taste the Difference 400g\n",
      "Got the text Sainsbury's Giraffe Bread (Tiger) 800g\n",
      "Got the text Sainsbury's Kalamata Olive Bread Taste the Difference 400g\n",
      "Got the text Sainsbury's Giraffe Bread (Tiger) 400g\n",
      "Got the text Sainsbury's Multiseed Loaf Taste the Difference 400g\n",
      "Got the text Sainsbury's Farmhouse Loaf White Bread 800g\n",
      "Got the text Sainsbury's San Francisco Style Sourdough Taste the Difference 400g\n",
      "Got the text Sainsbury's Sandwich Loaf White Bread 800g\n",
      "Got the text Sainsbury's White Bread SO Organic 400g\n",
      "Got the text Sainsbury's Pain De Campagne, Taste the Difference 400g\n",
      "Got the text Sainsbury's Hand-Crafted Sourdough Bloomer, Taste The Difference 400g\n",
      "Got the text Sainsbury's White Bloomer 400g\n",
      "Got the text Sainsbury's White Bloomer 800g\n",
      "Got the text Sainsbury's Stonebaked White Baton, Taste the Difference\n",
      "Got the text Tesco Hi Fibre Wholemeal Loaf 800G\n",
      "Got the text Tesco Hi Fibre Malted Loaf 800G\n",
      "Got the text Tesco Hi Fibre Malted Loaf 800G Sliced\n",
      "Got the text Tesco Hi Fibre Wholemeal Loaf 800G Sliced\n",
      "Got the text Tesco Hi Fibre Wholemeal Loaf 400G\n",
      "Got the text Tesco Hi Fibre Wholemeal Loaf 400G Sliced\n",
      "Got the text Tesco Hi Fibre Malted Loaf 400G\n",
      "Got the text Tesco Hi Fibre Malted Loaf 400G Sliced\n",
      "Got the text Hovis Granary Wholemeal Bread 800G\n",
      "Got the text Hovis Wholemeal Thick Bread 800G\n",
      "Got the text Hovis Wholemeal Medium Bread 800G\n",
      "Got the text Kingsmill Tasty Wholemeal Medium Bread 800G\n",
      "Got the text Warburtons Wholemeal Medium Bread 800G\n",
      "Got the text Tesco Finest Wholemeal Loaf 800G\n",
      "Got the text Tesco Wholemeal Medium Bread 800G\n",
      "Got the text Tesco Toastie Wholemeal Thick Bread 800G\n",
      "Got the text H W Nevills Wholemeal Bread 800G\n",
      "Got the text Sainsbury's Medium Sliced Wholemeal Bread 800g\n",
      "Got the text Sainsbury's Soft Multiseed Farmhouse Thick Sliced Wholemeal Bread, Taste the Difference 800g\n",
      "Got the text Warburtons Medium Sliced Wholemeal Bread 400g\n",
      "Got the text Hovis Medium Sliced Wholemeal Bread 800g\n",
      "Got the text Warburtons Medium Sliced Wholemeal Bread 800g\n",
      "Got the text Hovis Nimble Medium Sliced Wholemeal Bread 400g\n",
      "Got the text Hovis Thick Sliced Wholemeal Bread 800g\n",
      "Got the text Sainsbury's Thick Sliced Wholemeal Bread 800g\n",
      "Got the text Allinson The Champion Medium Sliced Wholemeal Bread 650g\n",
      "Got the text Daily's Medium Sliced Wholemeal Bread 800g\n",
      "Got the text Sainsbury's Soft Multiseed Wholemeal, Taste the Difference 430g\n",
      "Got the text Hovis Medium Sliced Wheatgerm Bread 400g\n",
      "Got the text Warburtons Danish Lighter Wholemeal Bread 400g\n",
      "Got the text Sainsbury's Wholemeal Bread Medium 400g\n",
      "Got the text Kingsmill No Crusts Medium Sliced Wholemeal Bread 400g\n",
      "Got the text Warburtons Wholemeal Thick Bread 400g\n",
      "Got the text Schar Gluten Free Wholesome Seeded Loaf 300g\n",
      "Got the text Warburtons Speciality Multi Grain and Seed Bread 400g\n",
      "Got the text Hovis Granary Cob 450g\n",
      "Got the text Warburtons Big 21 Seeds 700g\n",
      "Got the text Warburtons Plant Power 700g\n",
      "Got the text Vogel Seeded Wholemeal Bread 800g\n",
      "Got the text Hi-Lo Seeded Medium Sliced Wholemeal Bread 400g\n",
      "Got the text Promise Gluten Free Chia and Quinoa Loaf 480g\n",
      "Got the text Mcdougalls Self Raising Flour 11Kg\n",
      "Got the text Homepride Self Raising Flour 1Kg\n",
      "Got the text Doves Farm Gluten Free Self Raising 1Kg\n",
      "Got the text Tesco Organic Self Raising Flour 1Kg\n",
      "Got the text Tesco Self Raising Flour 15Kg\n",
      "Got the text Stockwell  Co Self Raising Flour 15Kg\n",
      "Got the text Allinson Wholemeal Self Raising Flour 1Kg\n",
      "Got the text Matthews Flour Organic Super Fine Self Raising Flour 15Kg\n",
      "Got the text Sainsbury's Self Raising Flour 1.5kg\n",
      "Got the text Homepride Extra Fine Self Raising Flour, Stay Fresh Pack 1kg\n",
      "Got the text Sainsbury's Self Raising Flour 500g\n",
      "Got the text Freee Gluten Free Self Raising White Flour 1kg\n",
      "Got the text McDougalls Self Raising Flour 1.1kg\n",
      "Got the text McDougalls Speciality Supreme Sponge Self Raising Flour 1kg\n",
      "Got the text Allinson Wholemeal Self Raising Flour 1kg\n",
      "Got the text Sainsbury's Cream of Tartar 160g\n",
      "Got the text Doves Farm Organic White Self Raising Flour 1kg\n",
      "Got the text Doves Farm Organic Self Raising Wholemeal Flour 1kg\n",
      "Got the text Elephant Atta Medium Chapatti Flour 10Kg\n",
      "Got the text Tesco Finest Abbv Very Strong Bread Flour 1Kg\n",
      "Got the text Tesco Medium Chapatti Flour 5Kg\n",
      "Got the text Tesco Wholemeal Chapatti Flour 10Kg\n",
      "Got the text Tesco Focaccia Bread Mix 500G 500G\n",
      "Got the text Tesco Ciabatta Bread Mix 500G 500G\n",
      "Got the text Tesco Oat  Linseed Bread Mix 500G\n",
      "Got the text Tesco Plain Flour 15Kg\n",
      "Got the text Stockwell  Co Plain Flour 15Kg\n",
      "Got the text Doves Farm Organic Oat Flour 450G\n",
      "Got the text Doves Farm Organic Wholemeal 1Kg Buckwheat Flour\n",
      "Got the text Doves Farm Organic Malthouse Flour Bread 1Kg\n",
      "Got the text Doves Farm Organic White Spelt Flour 1Kg\n",
      "Got the text Matthews Flour Eight Grain Strong Multigrain 15Kg\n",
      "Got the text Doves Farm Organic Rye Flour 1Kg\n",
      "Got the text Doves Farm Organic White Rye Flour 1Kg\n",
      "Got the text Matthews Flour Stone Ground Dark Rye Flour 15Kg\n",
      "Got the text Matthews Flour Premium White Strong Flour 15Kg\n",
      "Got the text Allinsons Garlic  Herb Naan Bread Kit 237G\n",
      "Got the text Matthews Cotswold Strong Crunch Flour 15Kg\n",
      "Got the text Homepride Premium Milled Extra Fine Flour 1Kg\n",
      "Got the text Matthews Flour Organic Plain Fine Flour 15Kg\n",
      "Got the text Matthews Flour Organic Super Fine Self Raising Flour 15Kg\n",
      "Got the text Tesco Cornflour 500G\n",
      "Got the text Doves Farm Organic Spelt Wholemeal Flour 1Kg\n",
      "Got the text Doves Farm Organic Brown Rice Flour 290G\n",
      "Got the text Elephant Atta Chapatti Flour Wholemeal 10Kg\n",
      "Got the text Brown  Polson Cornflour 500G\n",
      "Got the text Allinson Wholemeal Plain Flour 1Kg\n",
      "Got the text Mcdougalls Plain Flour 11Kg\n",
      "Got the text Matthews Flour Stoneground Strong Wholegrain 15Kg\n",
      "Got the text Sainsbury's Plain Flour 1.5kg\n",
      "Got the text Sainsbury's Strong White Unbleached Bread Flour 1.5kg\n",
      "Got the text Sainsbury's Plain Flour 500g\n",
      "Got the text Sainsbury's Strong White Unbleached Bread Flour 1.5kg\n",
      "Got the text Sainsbury's Strong Stoneground 100% Wholemeal Flour 1.5kg\n",
      "Got the text Homepride Extra Fine Plain Flour, Stay Fresh Pack 1kg\n",
      "Got the text Sainsbury's Wholegrain Seeded Flour, Taste the Difference 1kg\n",
      "Got the text Allinson Country Grain Bread Flour 1kg\n",
      "Got the text Freee Gluten Free Plain White Flour 1kg\n",
      "Got the text Doves Farm Organic Strong White Flour 1.5kg\n",
      "Got the text Allinson White Strong Bread Flour 3kg\n",
      "Got the text McDougalls Plain Flour 1.1kg\n",
      "Got the text Doves Farm Organic White Flour 1kg\n",
      "Got the text Doves Farm Organic Wholemeal Spelt Flour 1kg\n",
      "Got the text McDougalls Instant Thickening Granules 170g\n",
      "Got the text Carrs Breadmaker Strong White Flour 1.5kg\n",
      "Got the text Sainsbury's Strong Brown Flour 1.5kg\n",
      "Got the text Sainsbury's Very Strong Canadian Bread Flour, Taste the Difference 1kg\n",
      "Got the text Groovy Food Company Coconut Sugar Organic 500G\n",
      "Got the text Tesco Dark Brown Soft Sugar 1Kg Bag\n",
      "Got the text Tesco Light Brown Soft Sugar 1Kg Pack\n",
      "Got the text Silver Spoon Caster Sugar 1Kg\n",
      "Got the text Silver Spoon Jam Sugar 1Kg\n",
      "Got the text Pure Via Sugar Free Demerara Alternative 200G\n",
      "Got the text Pure Via Bakers Secret Icing Sugar Alternative 220G\n",
      "Got the text Billingtons Demerara Sugar 1Kg\n",
      "Got the text Silver Spoon Icing Sugar 1Kg\n",
      "Got the text Tesco Golden Caster 1Kg Bag\n",
      "Got the text Billingtons Molasses Sugar 500G\n",
      "Got the text Tesco Demerara Sugar 1Kg\n",
      "Got the text Tesco Golden Granulated Sugar 1Kg\n",
      "Got the text Billingtons Demerara Sugar 500G\n",
      "Got the text Billingtons Demerara Rough Cut Cubes 500G\n",
      "Got the text Billingtons Golden Granulated Sugar 1Kg\n",
      "Got the text Billingtons Light Brown Sugar 500G\n",
      "Got the text Billingtons Dark Muscovado 500G\n",
      "Got the text Billingtons Light Muscovado 500G\n",
      "Got the text Canderel Caster Sugar  Sweetener Blend 370G\n",
      "Got the text Silver Spoon Granulated Sugar 5Kg\n",
      "Got the text Trade Aid Uk Pure Cane Caster Sugar 1Kg\n",
      "Got the text Silver Spoon Royal Icing Sugar 500G\n",
      "Got the text Billingtons Golden Caster 1Kg\n",
      "Got the text Sainsbury's White Granulated Sugar 1kg\n",
      "Got the text Sainsbury's Fairtrade White Granulated Sugar 1kg\n",
      "Got the text Sainsbury's White Granulated Sugar 500g\n",
      "Got the text Sainsbury's White Granulated Sugar 5kg\n",
      "Got the text Sainsbury's Fairtrade Golden Granulated Sugar 1kg\n",
      "Got the text Tate & Lyle Fairtrade Cane Sugar White Cubes 500g\n",
      "Got the text Billington's Golden Granulated Sugar 1kg\n",
      "Got the text Silver Spoon Half Spoon Granulated Sugar 1kg\n",
      "Got the text Silver Spoon Half Spoon Granulated Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade Cane Sugar, SO Organic 500g\n",
      "Got the text The Groovy Food Company Organic Coconut Sugar 500g\n",
      "Got the text Sainsbury's White Caster Sugar1kg\n",
      "Got the text Sainsbury's Fairtrade Golden Caster Sugar 1kg\n",
      "Got the text Sainsbury's White Caster Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade White Caster Sugar 1kg\n",
      "Got the text Billington's Natural Golden Caster, Unrefined Cane Sugar 1kg\n",
      "Got the text Billington's Golden Caster Natural Unrefined Cane Sugar 250g\n",
      "Got the text Truvia Caster for Baking 360g\n",
      "Got the text Sainsbury's Fairtrade Light Soft Brown Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade Demerara Cane Sugar 1kg\n",
      "Got the text Sainsbury's Fairtrade Demerara Cane Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade Golden Granulated Sugar 1kg\n",
      "Got the text Sainsbury's Fairtrade Dark Soft Brown Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade Demerara Cane Sugar 2kg\n",
      "Got the text Sainsbury's Fairtrade Light Brown Soft Sugar 1kg\n",
      "Got the text Billington's Golden Granulated Sugar 1kg\n",
      "Got the text Billington's Light Muscovado Sugar 500g\n",
      "Got the text Billington's Demerara Sugar 500g\n",
      "Got the text Sainsbury's Fairtrade Dark Soft Brown Sugar 1kg\n",
      "Got the text Billington's Demerara Natural Unrefined Cane Sugar 250g\n",
      "Got the text Billington's Dark Muscovado Sugar 500g\n",
      "Got the text Billington's Light Brown Soft Natural Unrefined Cane Sugar 500g\n",
      "Got the text Lindt Lindor Milk Chocolate Truffles Carton 200G\n",
      "Got the text Ferrero Rocher 24 Pieces Boxed Chocolates 300G\n",
      "Got the text Cadbury Dairy Milk Chocolate Bar 360G\n",
      "Got the text Lindt Excellence Dark 70 Cocoa Chocolate Bar 100G\n",
      "Got the text Ferrero Rocher 16 Pieces Boxed Chocolates 200G\n",
      "Got the text Maltesers Gift Box Chocolates 310G\n",
      "Got the text Celebrations Chocolates 300G\n",
      "Got the text Cadbury Delights Nougat Salted Caramel Chocolate 5X22g\n",
      "Got the text Cadbury Delights Soft Nougat Hazelnut 5X22g\n",
      "Got the text Cadbury Delights Soft Nougat Orange  Caramel 5X22g\n",
      "Got the text Tesco Classic 74 Dark Chocolate 100G\n",
      "Got the text Nestle Kit Kat Chunky Milk Chocolate Bars Multipack 4 X 40g\n",
      "Got the text Smarties Chocolate Multipack 4 X 34G\n",
      "Got the text Maltesers Milk Chocolate Box 110G\n",
      "Got the text Cadbury Flake Chocolate Bars Multipack 4 X 255g\n",
      "Got the text Cadbury Dairy Milk Giant Buttons Chocolate Bag 119G\n",
      "Got the text Cadbury Twirl Chocolate Bars Multipack 4 X 34g\n",
      "Got the text Cadbury Dairy Milk For Kids 6 Pack 108G\n",
      "Got the text Cadbury Dairy Milk Caramel Chocolate Bars Multipack 4 X 37g\n",
      "Got the text Tesco Dark Chocolate Bar 200G\n",
      "Got the text Tesco Milk Chocolate Raisins 200G\n",
      "Got the text Tesco Milk Chocolate Peanut 200G\n",
      "Got the text Tesco Milk Chocolate Bar 200G\n",
      "Got the text Tesco Crunchy Caramel Chocolate Bars Multipack 5 X 42g\n",
      "Got the text Tesco Dreamy Caramel Chocolate Bars Multipack 6 X 40g\n"
     ]
    }
   ],
   "source": [
    "COLS = [\"CATEGORY\", \"NAME\"]\n",
    "df = pd.read_csv('../Data/SingleDataset.csv', names=COLS, index_col=False)\n",
    "df.head() \n",
    "\n",
    "accuate_results = 0 \n",
    "total_results = 0\n",
    "for index, row in df.iterrows():\n",
    "    text_string = row[\"NAME\"]\n",
    "    result = prediction_loop(text=text_string, models=models, label_dicts=label_dicts)\n",
    "    if row[\"CATEGORY\"] == result:\n",
    "        accuate_results += 1\n",
    "    total_results += 1\n",
    "\n",
    "accuracy = accuate_results/total_results \n",
    "\n",
    "print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
